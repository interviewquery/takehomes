Training data: 1000 observations of 452 predictors.
training models (random forest, linear regression, mean model)
head of data:
   index        x0        x1        x2        x3        x4        x5  \
0   1742  3.235293 -2.200589 -2.380482 -1.345628 -1.292009  2.469562   
1    567 -0.060205 -0.111817  0.059556  1.264099 -5.505889 -5.285825   
2    734  1.437538 -4.018748 -0.830913  4.849145  2.595604 -2.408200   

         x6        x7        x8    ...          x442       x443      x444  \
0 -0.270366 -3.835496 -6.246872    ...      7.272104   2.731022  2.379034   
1  0.883101  0.275059  1.858046    ...     -7.295405  -2.006847  4.204204   
2  8.187968  2.020299  1.131962    ...      4.463734  10.746530  3.584629   

       x445      x446      x447      x448       x449  category          y  
0  9.693820 -2.125123  2.520191  3.113814  -5.790193   group_7  35.856987  
1  4.280122 -3.332481 -1.864467  3.697249  -8.867053  group_37  27.014647  
2 -4.341093  3.853219 -1.162425  3.797865  10.280973  group_31  21.531396  

[3 rows x 453 columns]
head of categorical mapping (mapping from category string to additional X values):
   index  categorical_x0  categorical_x1  categorical_x10  categorical_x11  \
0      0       -1.513536       -2.301098         0.558601         1.397382   
1      1        0.828884        0.512237        -0.186961         0.625110   
2      2        0.826484       -0.456473         1.434223        -0.697900   

   categorical_x12  categorical_x13  categorical_x14  categorical_x15  \
0         0.171980        -0.389096        -0.803502         0.179462   
1        -0.796761        -0.135966         0.135827         0.282637   
2         0.451566         0.271715        -1.227876        -1.253258   

   categorical_x16    ...     categorical_x46  categorical_x47  \
0        -0.122052    ...           -0.204768         0.492253   
1         1.676717    ...           -0.207543         0.688260   
2         1.716382    ...            0.359860         0.136558   

   categorical_x48  categorical_x49  categorical_x5  categorical_x6  \
0         0.141082        -0.458428       -1.464948       -0.284549   
1         1.166832        -1.009547        1.103469       -0.447322   
2         1.047622        -0.920907        0.060573        0.012480   

   categorical_x7  categorical_x8  categorical_x9  category  
0       -0.239787        0.098923       -0.893566   group_0  
1       -0.322807        0.043577        0.096010   group_1  
2        0.555510       -0.397149        0.089028   group_2  

[3 rows x 52 columns]
head of X:
   index        x0        x1        x2        x3        x4        x5  \
0   1742  3.235293 -2.200589 -2.380482 -1.345628 -1.292009  2.469562   
1    567 -0.060205 -0.111817  0.059556  1.264099 -5.505889 -5.285825   
2    734  1.437538 -4.018748 -0.830913  4.849145  2.595604 -2.408200   

         x6        x7        x8    ...         x441      x442       x443  \
0 -0.270366 -3.835496 -6.246872    ...    -0.028984  7.272104   2.731022   
1  0.883101  0.275059  1.858046    ...    -3.006149 -7.295405  -2.006847   
2  8.187968  2.020299  1.131962    ...    -7.289180  4.463734  10.746530   

       x444      x445      x446      x447      x448       x449  category  
0  2.379034  9.693820 -2.125123  2.520191  3.113814  -5.790193   group_7  
1  4.204204  4.280122 -3.332481 -1.864467  3.697249  -8.867053  group_37  
2  3.584629 -4.341093  3.853219 -1.162425  3.797865  10.280973  group_31  

[3 rows x 452 columns]
selecting Xs that are correlated with y (abs correlation > 0.1)
 selected 23 predictors (columns of X): indices 1, 3, 4, 5, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 206, 226, 229, 233, 236, 241, 242, 243, 244
fitting random forest to training data
random forest feature importance (top 20 predictors by importance):
    corr_with_y  importance  predictor_index predictor_name
12     0.300622    0.109452               19            x18
9      0.294773    0.107966               16            x15
10     0.300569    0.099687               17            x16
5      0.202339    0.073888               11            x10
2      0.146954    0.064707                4             x3
13    -0.126583    0.057143               20            x19
17     0.124363    0.048059              233           x232
6      0.146271    0.046062               12            x11
1      0.181441    0.042553                3             x2
8      0.119582    0.042059               14            x13
18     0.115644    0.038920              236           x235
7     -0.108716    0.038666               13            x12
19     0.212825    0.034002              241           x240
0      0.117407    0.029615                1             x0
4      0.182639    0.029207                8             x7
3      0.107895    0.021339                5             x4
11     0.144394    0.021022               18            x17
20     0.236192    0.020857              242           x241
21     0.116980    0.019775              243           x242
16     0.106330    0.016972              229           x228
fitting linear regression to training data
fitting mean model to training data (mean of training data)
corr(y, rf_predictions) on new data: 0.260948469547
corr(y, linear_predictions) on new data: 0.641373877205
error estimates by model:
 linear regression: train 84.9106953647, test 86.7312913827, new data 97.3442567267
 random forest: train 7.41711809807e-30, test 208.269113062, new data 226.81285912
 mean model : train 173.298242516, test 171.977113084, new data 163.847782962
all done
